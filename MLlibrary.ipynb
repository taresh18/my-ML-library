{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taresh18/my-ML-library/blob/master/MLlibrary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K3L5P9Uu2Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7gvcqiovCKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLlibrary(object):  # parent class containing the common functions used in algorithms\n",
        "\n",
        "    def __init__(self, train_data_filename, test_data_filename):\n",
        "        self.train_data_filename = train_data_filename\n",
        "        self.test_data_filename = test_data_filename\n",
        "\n",
        "    def load_dataset(self):  # creating dataframes of train and test dataset\n",
        "        train_dataset = pd.read_csv(self.train_data_filename)\n",
        "        test_dataset = pd.read_csv(self.test_data_filename)\n",
        "        train_and_test = [train_dataset, test_dataset]\n",
        "        return train_and_test\n",
        "\n",
        "    def data_initialisation(self, train_and_test=None):  # extracting features and targets from input dataset\n",
        "        train_and_test = self.load_dataset()\n",
        "        train_feature_matrix = np.array(train_and_test[0])\n",
        "        test_feature_matrix = np.array(train_and_test[1])\n",
        "\n",
        "        # adding an additional column to features arrays to account for biased features\n",
        "        train_feature_matrix = train_feature_matrix[:, 1:]\n",
        "        test_feature_matrix = test_feature_matrix[:, 1:]\n",
        "        train_features = np.ones((np.shape(train_feature_matrix)[0], np.shape(train_feature_matrix)[1] + 1), dtype=int)\n",
        "        test_features = np.ones((np.shape(test_feature_matrix)[0], np.shape(test_feature_matrix)[1] + 1), dtype=int)\n",
        "        train_features[:, 1:] = train_feature_matrix\n",
        "        test_features[:, 1:] = test_feature_matrix\n",
        "\n",
        "        train_target_matrix = np.array(train_and_test[0])\n",
        "        test_target_matrix = np.array(train_and_test[1])\n",
        "\n",
        "        train_target_matrix = train_target_matrix[:, 0]\n",
        "        test_target_matrix = test_target_matrix[:, 0]\n",
        "\n",
        "        arrays = [train_features, test_features, train_target_matrix, test_target_matrix]\n",
        "        # converting arrays to well shaped numpy vectors\n",
        "        arrays[2] = np.array([arrays[2]])\n",
        "        arrays[2] = np.transpose(arrays[2])\n",
        "        arrays[3] = np.array([arrays[3]])\n",
        "        arrays[3] = np.transpose(arrays[3])\n",
        "        return arrays\n",
        "\n",
        "    def mean_normalization(self, arrays=None):  # applying mean normalisation on features\n",
        "        arrays = self.data_initialisation()\n",
        "        arrays[0] = ((arrays[0] - np.mean(arrays[0])) / (np.max(arrays[0]) - np.min(arrays[0])))\n",
        "        arrays[1] = ((arrays[1] - np.mean(arrays[1])) / (np.max(arrays[1]) - np.min(arrays[1])))\n",
        "        return arrays"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYELCyoGvCpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearRegression(MLlibrary):  # class for Linear Regression\n",
        "\n",
        "    def split_data(self, train_features, train_target, split_ratio=0.8): # split training data into training and cross validation\n",
        "        m = np.shape(train_features)[0]\n",
        "        split_at = int(m * split_ratio)\n",
        "        X_train = train_features[:split_at, :]\n",
        "        Y_train = train_target[:split_at, :]\n",
        "        X_cv = train_features[split_at:, :]\n",
        "        Y_cv = train_target[split_at:, :]\n",
        "        return X_train, Y_train, X_cv, Y_cv\n",
        "\n",
        "    def hypothesis(self, X, theta):\n",
        "        hypothesis = np.dot(X, theta)\n",
        "        return hypothesis\n",
        "\n",
        "    def cost_function(self, X, theta, y, lamda):\n",
        "        hypothesis = self.hypothesis(X, theta)\n",
        "        m = X.shape[0]\n",
        "        theta_without_zero = theta[1:, :]\n",
        "        mean_squared_error = np.square(hypothesis - y)\n",
        "        cost_function = (np.sum(mean_squared_error) + lamda * np.sum(theta_without_zero))/(2.0 * m)\n",
        "        return cost_function\n",
        "\n",
        "    def gradient_descent(self, X, theta, y, lamda, alpha):\n",
        "        m = np.shape(X)[0]\n",
        "        hypothesis = self.hypothesis(X, theta)\n",
        "        theta = theta - (alpha / m) * (np.dot(np.transpose(X), (hypothesis - y)) + lamda * theta)\n",
        "        return theta\n",
        "\n",
        "    def training(self, iterations, X_train, Y_train, lamda, alpha):\n",
        "        cost_history = []\n",
        "        theta = np.zeros((np.shape(X_train)[1], 1))\n",
        "        for iteration in range(iterations):\n",
        "            theta = self.gradient_descent(X_train, theta, Y_train, lamda, alpha)\n",
        "            cost = self.cost_function(X_train, theta, Y_train, lamda)\n",
        "            cost_history.append(cost)\n",
        "        return theta, cost_history\n",
        "\n",
        "    def predicting(self, X, Y, iterations, lamda, alpha):\n",
        "        [theta, cost_history] = self.training(iterations, X, Y, lamda, alpha)\n",
        "        prediction = self.hypothesis(X, theta)\n",
        "        prediction = np.round(prediction, 0)  # rounds the prediction value to its nearest integer\n",
        "        return prediction, cost_history\n",
        "\n",
        "    def plots(self, cost_history, iterations):  # to plot cost function with iterations\n",
        "        iteration = []\n",
        "        for i in range(iterations):\n",
        "            iteration.append(i)\n",
        "        plt.grid(True)\n",
        "        plt.scatter(iteration, cost_history, marker=\"x\")\n",
        "        plt.xlabel('no of iterations')\n",
        "        plt.ylabel('cost_train')\n",
        "        plt.show()\n",
        "\n",
        "    def accuracy(self, prediction, Y):  # to calculate accuracy on predictions\n",
        "        m = Y.shape[0]\n",
        "        count = 0\n",
        "        for i in range(np.shape(Y)[0]):\n",
        "            if (prediction[i][0] == Y[i][0]): \n",
        "              count += 1\n",
        "        accuracy = float(count) / m\n",
        "        return accuracy * 100\n",
        "\n",
        "    def LinearRegression(self, iterations, alpha, lamda):\n",
        "        arrays = self.mean_normalization()\n",
        "        [X_train, Y_train, X_cv, Y_cv] = self.split_data(arrays[0], arrays[2])\n",
        "        [X_test, Y_test] = [arrays[1], arrays[3]]\n",
        "\n",
        "        [prediction_train, cost_history] = self.predicting(X_train, Y_train, iterations, lamda, alpha)\n",
        "        prediction_cv = self.predicting(X_cv, Y_cv, iterations, lamda, alpha)[0]\n",
        "        prediction_test = self.predicting(X_test, Y_test, iterations, lamda, alpha)[0]\n",
        "\n",
        "        accuracy_train = self.accuracy(prediction_train, Y_train)\n",
        "        accuracy_cv = self.accuracy(prediction_cv, Y_cv)\n",
        "        accuracy_test = self.accuracy(prediction_test, Y_test)\n",
        "\n",
        "        self.plots(cost_history, iterations)\n",
        "\n",
        "        print(accuracy_train, accuracy_cv, accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk5pwx4-9J17",
        "colab_type": "code",
        "outputId": "0705ecfb-96bf-4b1c-a470-0418bb8877b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "a = LinearRegression(r\"/content/sample_data/mnist_train_small.csv\",\n",
        "                     r\"/content/sample_data/mnist_test.csv\")\n",
        "\n",
        "a.LinearRegression(1000, 0.03, 20)  # parameters to pass=(iterations, learning rate, regularisation parameter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEJCAYAAAB2T0usAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJkZ8P8BHHX+ygZOFS4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "21.320082505156574 21.325 21.47214721472147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kUyC8bkk0XF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(MLlibrary):  # class for Linear Regression\n",
        "\n",
        "    def split_data(self, train_features, train_target,  split_ratio = 0.8):  # split training data into training and cross validation\n",
        "        m = np.shape(train_features)[0]\n",
        "        split_at = int(m * split_ratio)\n",
        "        X_train = train_features[:split_at, :]\n",
        "        Y_train = train_target[:split_at, :]\n",
        "        X_cv = train_features[split_at:, :]\n",
        "        Y_cv = train_target[split_at:, :]\n",
        "        return X_train, Y_train, X_cv, Y_cv\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        sigmoid = 1 / (1 + np.exp(-z))\n",
        "        return sigmoid\n",
        "\n",
        "    def hypothesis(self, X, theta):\n",
        "        z = np.dot(X, theta)\n",
        "        hypothesis = self.sigmoid(z)\n",
        "        return hypothesis\n",
        "\n",
        "    def CostFunction(self, X, y, theta, lamda):  # returns log loss cost function with regularization \n",
        "        m = np.shape(y)[0]\n",
        "        log_loss = (- y * np.log(self.hypothesis(X, theta))) - ((1 - y) * np.log(1 - self.hypothesis(X, theta)))\n",
        "        cost_function = (1 / m) * np.sum(log_loss) + (lamda / (2 * m)) * np.sum(np.square(theta[1:]))\n",
        "        return cost_function\n",
        "\n",
        "    def gradient(self, X, y, theta, lamda):  # returns gradient to be used in updating parameters\n",
        "        m = np.shape(y)[0]\n",
        "        j_0 = 1 / m * np.dot(X.T, (self.hypothesis(X, theta) - y))[0]  # not including regularization term in biased parameters\n",
        "        j_1 = 1 / m * np.dot(X.T, (self.hypothesis(X, theta) - y))[1:] + (lamda / m) * theta[1:]\n",
        "        gradient = np.vstack((j_0[:, np.newaxis], j_1))\n",
        "        return gradient\n",
        "\n",
        "    def GradientDescent(self, X, y, theta, alpha, iterations, lamda):\n",
        "        m = np.shape(y)[0]\n",
        "        cost_history = np.zeros((iterations, 1))\n",
        "\n",
        "        for i in range(iterations):\n",
        "            cost = self.CostFunction(X, y, theta, lamda)\n",
        "            gradient = self.gradient(X, y, theta, lamda)\n",
        "            theta = theta - (alpha * gradient)\n",
        "            cost_history[i, 0] = cost\n",
        "\n",
        "        return theta, cost_history\n",
        "\n",
        "    def classifier(self, X, y, alpha, iterations, num_classes, lamda):  # implement one Vs. all classification\n",
        "        m, n = X.shape[0], X.shape[1]\n",
        "        initial_theta = np.zeros((n, 1))\n",
        "        all_theta = []\n",
        "        all_costs = np.zeros((iterations, num_classes))\n",
        "\n",
        "        for i in range(num_classes):\n",
        "            # convert target values into classes by one-hot encoding\n",
        "            y_into_classes = np.where(y == i, 1, 0)  \n",
        "            # find parameters and cost history for each individual class\n",
        "            theta, cost_history = self.GradientDescent(X, y_into_classes, initial_theta, alpha, iterations, lamda)\n",
        "            all_theta.extend(theta)\n",
        "            # putting cost history of individual classes into separate columns of all_J\n",
        "            all_costs[:, [i]] = cost_history\n",
        "        return np.array(all_theta).reshape(num_classes, n), all_costs\n",
        "\n",
        "    def predicting(self, all_theta, X):\n",
        "        m = np.shape(X)[0]\n",
        "        probabilities = np.dot(X, all_theta.T)\n",
        "        predictions = np.argmax(probabilities, axis=1)  # returns the index(class) having the maximum probability\n",
        "        predictions = np.array([predictions])\n",
        "        predictions = predictions.T\n",
        "        return predictions\n",
        "\n",
        "    def plot(self, cost_history, iterations):  # to plot cost function with iterations\n",
        "        iteration = []\n",
        "        for i in range(iterations):\n",
        "            iteration.append(i)\n",
        "        iterations = np.array([iterations])\n",
        "        iterations = iterations.T\n",
        "        plt.grid(True)\n",
        "        plt.scatter(iteration, cost_history, marker=\"x\")\n",
        "        plt.xlabel('no of iterations')\n",
        "        plt.ylabel('cost_train')\n",
        "        plt.show()\n",
        "\n",
        "    def accuracy(self, prediction, Y):  # to calculate accuracy on predictions\n",
        "        m = Y.shape[0]\n",
        "        count = 0\n",
        "        for i in range(np.shape(Y)[0]):\n",
        "            if (prediction[i][0] == Y[i][0]):\n",
        "                count += 1\n",
        "        accuracy = float(count) / m\n",
        "        return accuracy * 100\n",
        "\n",
        "    def logistic_regression(self, alpha=0.03, iterations=1000, num_classes = 10, lamda = 1, ith_class = 1):\n",
        "        arrays = self.mean_normalization()\n",
        "        [X_train, Y_train, X_cv, Y_cv] = self.split_data(arrays[0], arrays[2])\n",
        "        [X_test, Y_test] = [arrays[1], arrays[3]]\n",
        "\n",
        "        [all_theta, all_costs] = self.classifier(X_train, Y_train, alpha, iterations, num_classes, lamda)\n",
        "\n",
        "        pred_train = self.predicting(all_theta, X_train)\n",
        "        pred_cv = self.predicting(all_theta, X_cv)\n",
        "        pred_test = self.predicting(all_theta, X_test)\n",
        "        accuracy_train = self.accuracy(pred_train, Y_train)\n",
        "        accuracy_cv = self.accuracy(pred_cv, Y_cv)\n",
        "        accuracy_test = self.accuracy(pred_test, Y_test)\n",
        "\n",
        "        print(accuracy_train, accuracy_cv, accuracy_test)\n",
        "        # plotting the cost history of ith class with no. of iterations\n",
        "        self.plot(all_costs[:, ith_class], iterations)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLrEm76loHp",
        "colab_type": "code",
        "outputId": "1e42c054-8a2a-4ea4-d613-d40484badda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "a = LogisticRegression(r\"/content/sample_data/mnist_train_small.csv\",\n",
        "                     r\"/content/sample_data/mnist_test.csv\")\n",
        "\n",
        "a.logistic_regression()  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.967997999875 87.25 87.998799879988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAqcgEBEJ3P8CmiJxU4s3Ma0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peeQ4plds4Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KNN(MLlibrary):  # class of KNN algorithm\n",
        "\n",
        "    def euclidean_distance(self, train_features_row, test_features_row):\n",
        "        squared_distance = np.sum(np.square(train_features_row - test_features_row))\n",
        "        distance = math.sqrt(squared_distance)\n",
        "        return distance\n",
        "\n",
        "    def finding_neighbours(self, train_features, train_target, test_features_row, k):\n",
        "        m = np.shape(train_features)[0]\n",
        "        distances = np.zeros((m, 2))\n",
        "        for ith_train_row in range(m):\n",
        "            distance = self.euclidean_distance(train_features[ith_train_row, :], test_features_row)\n",
        "            distances[ith_train_row, 0] = train_target[ith_train_row, 0]\n",
        "            distances[ith_train_row, 1] = distance\n",
        "        \n",
        "        abc = np.argsort(distances[:,1])\n",
        "        distances = distances[abc]\n",
        "        neighbours = np.zeros((k,1))\n",
        "        for i in range(k):\n",
        "            neighbours[i][0] = distances[i][0]\n",
        "\n",
        "        return neighbours\n",
        "\n",
        "    def predicting_class(self, train_features, train_target, test_features_row, k):\n",
        "        neighbours = self.finding_neighbours(train_features, train_target, test_features_row, k)\n",
        "        (values,counts) = np.unique(neighbours, return_counts=True)\n",
        "        ind = np.argmax(counts)\n",
        "        return values[ind]\n",
        "\n",
        "    def finding_predictions(self, train_features, train_target, test_features,  k):\n",
        "        m = np.shape(test_features)[0]\n",
        "        predictions = np.zeros((m, 1))\n",
        "        for ith_test_row in range(m):\n",
        "            test_feature_row = test_features[ith_test_row]\n",
        "            predictions[ith_test_row, 0] = (self.predicting_class(train_features, train_target, test_feature_row, k))\n",
        "        print(predictions)\n",
        "        print(test_target)\n",
        "\n",
        "    def accuracy(self, train_features, train_target, test_features, test_target, k):  # calculate accuracy of prediction\n",
        "        predictions = self.finding_predictions(train_features, train_target, test_features, k)\n",
        "        m = np.shape(test_features)[0]\n",
        "        count = 0\n",
        "        for i in range(m):\n",
        "            if predictions[i][0] == test_target[i][0]:\n",
        "                count += 1\n",
        "        accuracy = float(count) / m\n",
        "        return accuracy\n",
        "\n",
        "    def KNN(self, k):\n",
        "        arrays = self.mean_normalization()\n",
        "        self.finding_predictions(arrays[0], arrays[2], arrays[1],  k)\n",
        "        #print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t19lbaWRtKse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = KNN(r\"/content/sample_data/mnist_train_small.csv\",\n",
        "                     r\"/content/sample_data/mnist_test.csv\")\n",
        "a.KNN(3)  # parameters to be passed = (value of K(no of nearest neighbours))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}